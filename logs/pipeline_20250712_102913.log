2025-07-12 10:29:13 | INFO     | utils.utils - Logging system initialized
2025-07-12 10:29:13 | INFO     | __main__ - ================================================================================
2025-07-12 10:29:13 | INFO     | __main__ - Chemical Kinetics Neural Network Pipeline
2025-07-12 10:29:13 | INFO     | __main__ - Configuration: config/config.jsonc
2025-07-12 10:29:13 | INFO     | utils.utils - Random seed set to 42
2025-07-12 10:29:13 | INFO     | utils.hardware - Using Apple Silicon MPS device
2025-07-12 10:29:13 | WARNING  | utils.hardware - MPS backend has limited operator support
2025-07-12 10:29:13 | WARNING  | utils.hardware - torch.compile is disabled for MPS devices
2025-07-12 10:29:13 | WARNING  | utils.hardware - Disabling torch.compile for MPS device due to compatibility issues
2025-07-12 10:29:13 | INFO     | __main__ - Starting data preprocessing …
2025-07-12 10:29:13 | INFO     | data.preprocessor - Processing 9 raw data files...
2025-07-12 10:29:13 | INFO     | data.preprocessor - Scanning files with 4 workers…
2025-07-12 10:29:33 | INFO     | data.preprocessor - Found 2,016,000 profiles × 100 timesteps
2025-07-12 10:29:33 | INFO     | data.preprocessor - Split sizes - Train: 1,411,200, Val: 302,400, Test: 302,400
2025-07-12 10:29:33 | INFO     | data.preprocessor - Creating flattened dataset …
2025-07-12 10:42:03 | INFO     | data.preprocessor - Parsed 5/9 files (55.6 %)
2025-07-12 10:47:03 | INFO     | data.preprocessor - Parsed 9/9 files (100.0 %)
2025-07-12 10:47:03 | WARNING  | data.preprocessor - Wrote 199,505,097 rows < expected 199,584,000; resizing dataset to actual length
2025-07-12 10:47:03 | INFO     | data.preprocessor - Flattening complete – 199,505,097 rows in 1,050.0 s (190,010 rows s⁻¹)
2025-07-12 10:47:05 | INFO     | __main__ - Computing normalisation statistics …
2025-07-12 10:47:05 | INFO     | data.normalizer - Calculating statistics from 1,411,200 rows in data/processed/dataset.h5
2025-07-12 10:47:05 | INFO     | data.normalizer - Using reservoir size 1,411,200 for symlog quantile estimation (100 timesteps × 1411200 profiles)
2025-07-12 10:47:17 | INFO     | data.normalizer - Statistics ready in 11.4s
2025-07-12 10:47:17 | INFO     | __main__ - Pre-processing complete.
2025-07-12 10:47:17 | INFO     | __main__ - Starting model training...
2025-07-12 10:47:18 | INFO     | __main__ - Model: DEEPONET
2025-07-12 10:47:18 | INFO     | __main__ - Parameters: 1,555,854
2025-07-12 10:47:18 | INFO     | __main__ - Creating datasets...
2025-07-12 10:47:18 | WARNING  | data.dataset - No train_sample_indices found, using all samples
2025-07-12 10:47:18 | INFO     | data.dataset - Using pre-flattened format with 199,505,097 samples
2025-07-12 10:47:18 | INFO     | data.dataset - Dataset initialized: 199,505,097 samples (split: train)
2025-07-12 10:47:18 | WARNING  | data.dataset - No validation_sample_indices found, using all samples
2025-07-12 10:47:18 | INFO     | data.dataset - Using pre-flattened format with 199,505,097 samples
2025-07-12 10:47:18 | INFO     | data.dataset - Dataset initialized: 199,505,097 samples (split: validation)
2025-07-12 10:47:18 | WARNING  | data.dataset - No test_sample_indices found, using all samples
2025-07-12 10:47:18 | INFO     | data.dataset - Using pre-flattened format with 199,505,097 samples
2025-07-12 10:47:18 | INFO     | data.dataset - Dataset initialized: 199,505,097 samples (split: test)
2025-07-12 10:47:19 | INFO     | training.trainer - Optimizer: AdamW with lr=5.00e-04, weight_decay=1.00e-05
2025-07-12 10:47:19 | INFO     | training.trainer - Scheduler: cosine
2025-07-12 10:47:19 | INFO     | training.trainer - Loss function: huber
2025-07-12 10:47:19 | WARNING  | training.trainer - MPS doesn't support bfloat16, using float16 instead
2025-07-12 10:47:19 | INFO     | training.trainer - GradScaler disabled on MPS (not supported)
2025-07-12 10:47:19 | INFO     | training.trainer - AMP enabled with dtype=float16 on mps device
2025-07-12 10:47:19 | INFO     | training.trainer - Starting training...
2025-07-12 10:47:19 | INFO     | training.trainer - Train batches: 3044
2025-07-12 10:47:19 | INFO     | training.trainer - Val batches: 3044
2025-07-12 10:55:48 | INFO     | training.trainer - Epoch 001   0.0%  Loss 7.1415e-02
2025-07-12 11:04:03 | INFO     | training.trainer - Epoch 001   0.1%  Loss 1.1547e-01
2025-07-12 11:12:29 | INFO     | training.trainer - Epoch 001   0.1%  Loss 8.7914e-02
