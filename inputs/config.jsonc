// =========================================================================================
// ==                 OPTIMIZED CONFIGURATION WITH AUTO-DETECTION                        ==
// =========================================================================================
// This configuration includes auto-configuration for optimal hardware utilization.

{
  // ════════════════════════════════════════════════════════════════
  // ║                1. DATA & OUTPUT PATHS CONFIGURATION          ║
  // ════════════════════════════════════════════════════════════════
  "data_paths_config": {
    "hdf5_dataset_filename": "chem_data/Xi_chem_data.h5",
    "dataset_splits_filename": "chem_data/Xi_chem_data_splits.json"
  },
  
  "output_paths_config": {
    "fixed_model_foldername": "trained_model_siren",
    "tuning_results_foldername": "tuning_runs_siren"
  },

  // ════════════════════════════════════════════════════════════════
  // ║                      2. DATA SPECIFICATION                   ║
  // ════════════════════════════════════════════════════════════════
  "data_specification": {
    // Chemical species that evolve over time
    "species_variables": [
      "C2H2_evolution", "CH4_evolution", "CO2_evolution", "CO_evolution",
      "H2O_evolution", "H2_evolution", "HCN_evolution", "H_evolution",
      "N2_evolution", "NH3_evolution", "OH_evolution", "O_evolution"
    ],
    
    // Global conditions (temperature, pressure)
    "global_variables": ["P", "T"],
    
    // All variables for normalization
    "all_variables": [
      "P", "T", "t_time",
      "C2H2_evolution", "CH4_evolution", "CO2_evolution", "CO_evolution",
      "H2O_evolution", "H2_evolution", "HCN_evolution", "H_evolution",
      "N2_evolution", "NH3_evolution", "OH_evolution", "O_evolution"
    ]
  },

  // ══════════════════════════════════════════════════════════════════
  // ║                    3. NORMALIZATION SETTINGS                     ║
  // ══════════════════════════════════════════════════════════════════
  "normalization": {
    "default_method": "log-standard",
    
    // Override for specific variables
    "key_methods": { 
      "T": "standard",           
      "P": "log-standard",          
      "t_time": "log-min-max"
    },
    
    // Symlog percentile for threshold determination
    "symlog_percentile": 0.2,
    
    // Memory limit for quantile methods
    "quantile_max_values_in_memory": 50000000
  },

  // ════════════════════════════════════════════════════════════════
  // ║              4. MODEL HYPERPARAMETER       ║
  // ════════════════════════════════════════════════════════════════
  "model_hyperparameters": {
    // Model architecture choice
    "model_type": "siren",  // Options: "mlp", "siren", "fno"
    
    // Network architecture - start conservative
    "hidden_dims": [256, 256, 256],  // 3 layers is often sufficient
    "dropout": 0.1,                  // Moderate regularization
    
    // Conditioning parameters
    "condition_dim": 64,
    "use_time_embedding": true,
    "time_embedding_dim": 32,
    
    // MLP-specific parameters
    "use_residual": true,
    "activation": "silu",           // Smooth activation
    "use_layer_norm": true,
    "init_type": "xavier_uniform",
    "stochastic_depth": 0.1,
    "use_gradient_checkpointing": "auto",  // Auto-detect based on GPU memory
    
    // SIREN-specific parameters (reduced for stability)
    "siren_w0_initial": 10.0,       // Reduced from 30.0
    "siren_w0_hidden": 1.0,         // Keep hidden layers stable
    "use_batch_norm": false,
    "final_activation": true,       // Helps bound outputs
    "siren_use_erf_approx": true,   // Prevent numerical issues
    
    // FNO-specific parameters
    "fno_spectral_modes": 16,
    "fno_seq_length": 32,
    "fno_compression": 0.5
  },

  // ════════════════════════════════════════════════════════════════
  // ║               5. TRAINING HYPERPARAMETERS                      ║
  // ════════════════════════════════════════════════════════════════
  "training_hyperparameters": {
    // Data split parameters
    "val_frac": 0.15,
    "test_frac": 0.15,
    
    // Start with small data fraction for testing, then increase
    "data_fraction": 1.0,           // Use full data
    
    // Training duration
    "epochs": 100,
    "early_stopping_patience": 20,
    "min_delta": 1e-6,
    
    // Batch settings - AUTO configured based on GPU
    "batch_size": "auto",           // Will auto-detect optimal size
    "gradient_accumulation_steps": "auto",  // Will target effective batch of 16384
    
    // Optimizer settings (AdamW only)
    "learning_rate": 1e-4,          // Conservative start
    "weight_decay": 1e-5,
    
    // Learning rate schedule (cosine or plateau only)
    "scheduler_choice": "cosine",   // Options: "cosine", "plateau"
    "warmup_epochs": 5,
    "patience": 10,                 // For plateau scheduler
    "factor": 0.5,                  // For plateau scheduler
    "min_lr": 1e-7,
    
    // Cosine scheduler settings
    "cosine_T_0": 20,
    "cosine_T_mult": 2,
    
    // Loss function (MSE or Huber only)
    "loss_function": "huber",       // Options: "mse", "huber"
    "huber_delta": 0.5,            // For Huber loss
    
    // Training stability
    "gradient_clip_val": 1.0,
    "gradient_clip_mode": "norm",   // "norm" or "value"
    
    // Mixed precision training - AUTO configured
    "use_amp": "auto",              // Will enable on capable GPUs
    
    // Loss tracking
    "max_invalid_batches": 100,     // Stop if too many NaN losses
    "invalid_batch_threshold": 0.5   // Stop if >50% batches are invalid
  },

  // ════════════════════════════════════════════════════════════════
  // ║              6. OPTUNA HYPERPARAMETER SEARCH                   ║
  // ════════════════════════════════════════════════════════════════
  "optuna_settings": {
    "study_name": "siren-kinetics-stable-v3",
    "n_trials": 200,
    "pruner_warmup_steps": 10,
    "pruner_startup_trials": 10,
    "gc_after_trial": true,
    "show_progress_bar": true
  },
  
  "optuna_hyperparam_search_space": {
    // Architecture search
    "architecture": {
      "num_hidden_layers": {"type": "int", "low": 2, "high": 5},
      "hidden_dim": {"type": "categorical", "choices": [128, 256, 384, 512]}
    },
    
    // Hyperparameter search
    "hyperparameters": {
      // Learning parameters
      "learning_rate": {"type": "float", "low": 1e-5, "high": 5e-4, "log": true},
      "weight_decay": {"type": "float", "low": 1e-7, "high": 1e-4, "log": true},
      "dropout": {"type": "float", "low": 0.0, "high": 0.3},
      
      // Regularization
      "stochastic_depth": {"type": "float", "low": 0.0, "high": 0.2},
      
      // Model-specific parameters (conservative ranges)
      "siren_w0_initial": {"type": "float", "low": 1.0, "high": 30.0},
      "siren_w0_hidden": {"type": "float", "low": 0.5, "high": 2.0},
      "condition_dim": {"type": "categorical", "choices": [32, 64, 128]},
      
      // Training settings
      "warmup_epochs": {"type": "int", "low": 0, "high": 10},
      "huber_delta": {"type": "float", "low": 0.1, "high": 1.0},
      
      // Activation functions (for MLP)
      "activation": {"type": "categorical", "choices": ["relu", "gelu", "silu", "elu"]},
      
      // Scheduler choice
      "scheduler_choice": {"type": "categorical", "choices": ["cosine", "plateau"]}
    }
  },

  // ════════════════════════════════════════════════════════════════
  // ║                   7. MISCELLANEOUS SETTINGS                    ║
  // ════════════════════════════════════════════════════════════════
  "miscellaneous_settings": {
    "random_seed": 42,
    
    // DataLoader settings - AUTO configured
    "num_dataloader_workers": "auto",    // Will be 0 for HDF5, otherwise optimized
    
    // Memory management - AUTO configured
    "profiles_per_chunk": "auto",        // Will be set based on available memory
    "max_memory_per_worker_gb": "auto",  // Will be set based on system memory
    
    // Dataset caching - AUTO configured
    "cache_dataset": "auto",             // Will cache if dataset fits in memory
    
    // Model compilation and export - AUTO configured
    "use_torch_compile": "auto",         // Will enable on capable GPUs
    "torch_compile_mode": "reduce-overhead",
    "export_jit_model": true,
    "export_jit_during_training": false,  // Only export at end
    
    "show_epoch_progress": true,
    
    // Debugging options
    "detect_anomaly": false,        // Enable for debugging NaN issues
    "log_gradient_norms": true,     // Track gradient health
    "save_checkpoint_every_n_epochs": 10
  }
}