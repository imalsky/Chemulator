{
  "normalization": {
    "methods": {
      "T": "min-max",
      "P": "log-min-max"
    },
    "default_method": "log-standard",
    "globals_default_method": "standard",
    "epsilon": 1e-30,
    "min_std": 1e-12
  },
  "data": {
    "species_variables": [
      "C2H2_evolution",
      "CH4_evolution",
      "CO2_evolution",
      "CO_evolution",
      "H2O_evolution",
      "H2_evolution",
      "HCN_evolution",
      "H_evolution",
      "N2_evolution",
      "NH3_evolution",
      "OH_evolution",
      "O_evolution"
    ],
    "global_variables": [
      "P",
      "T"
    ]
  },
  "dataset": {
    "windows_per_trajectory": 10,
    "preload_to_device": true,
    "shard_cache_size": 2,
    "use_mmap": true
  },
  "model": {
    "type": "mlp",
    "activation": "silu",
    "dropout": 0.0,
    "predict_delta": true,
    "layer_norm": true,
    "layer_norm_eps": 1e-05,
    "mlp": {
      "hidden_dims": [
        1024,
        1024,
        1024,
        1024,
        1024,
        1024
      ],
      "residual": true
    },
    "autoencoder": {
      "latent_dim": 256,
      "encoder_hidden": [
        512,
        512
      ],
      "dynamics_hidden": [
        512,
        512
      ],
      "decoder_hidden": [
        512,
        512
      ],
      "residual": true,
      "dynamics_residual": true
    }
  },
  "training": {
    "max_epochs": 600,
    "batch_size": 2048,
    "optimizer": {
      "name": "adamw",
      "lr": 1e-5,
      "weight_decay": 0.0001,
      "betas": [
        0.9,
        0.999
      ],
      "eps": 1e-08
    },
    "rollout_steps": 50,
    "burn_in": {
      "train": 3,
      "val": 3,
      "test": 3
    },
    "teacher_forcing": {
      "mode": "constant",
      "p0": 0.0,
      "p1": 0.0,
      "ramp_epochs": 0
    },
    "curriculum": {
      "enabled": false,
      "mode": "linear",
      "base_k": 2,
      "max_k": 50,
      "ramp_epochs": 250
    },
    "long_rollout": {
      "enabled": false,
      "long_rollout_steps": 300,
      "final_epochs": 40,
      "apply_to_validation": false,
      "apply_to_test": true
    },
    "loss": {
      "lambda_log10_mae": 1.0,
      "lambda_z_mse": 0.5
    },
    "scheduler": {
      "enabled": true,
      "type": "cosine_with_warmup",
      "warmup_epochs": 10,
      "min_lr_ratio": 0.01
    },
    "num_workers": 0,
    "pin_memory": false,
    "persistent_workers": false,
    "prefetch_factor": null,
    "resume": true,
    "autoregressive_training": {
      "enabled": true,
      "no_grad_steps": 10,
      "backward_per_step": true,
      "teacher_forcing_in_trained_steps": false
    }
  },
  "runtime": {
    "mode": "train",
    "checkpoint": "models/v2/checkpoints/last.ckpt",
    "precision": "bf16-mixed",
    "devices": "auto",
    "accelerator": "auto",
    "strategy": "auto",
    "gradient_clip_val": 0.0,
    "accumulate_grad_batches": 1,
    "log_every_n_steps": 50,
    "enable_progress_bar": true,
    "deterministic": false,
    "checkpointing": {
      "enabled": true,
      "save_top_k": 1,
      "monitor": "val_loss",
      "every_n_epochs": 1
    },
    "torch_compile": {
      "enabled": false,
      "backend": "inductor",
      "mode": "reduce-overhead",
      "dynamic": false,
      "fullgraph": false,
      "compile_forward_step": true,
      "compile_open_loop_unroll": false
    }
  },
  "preprocessing": {
    "drop_below": 1e-30,
    "dt": 100.0,
    "dt_sampling": "loguniform",
    "dt_mode": "per_chunk",
    "dt_min": 10.0,
    "dt_max": 100.0,
    "n_steps": 500,
    "t_min": 0.001,
    "time_keys": [
      "time",
      "t_time",
      "t"
    ],
    "output_trajectories_per_file": 1000,
    "val_split": 0.1,
    "test_split": 0.1,
    "shard_size": 16384,
    "time_key": "time",
    "species_group": "species",
    "globals_group": "globals"
  },
  "paths": {
    "raw_data_dir": "data/raw",
    "processed_dir": "data/processed",
    "work_dir": "models/v2_auto"
  },
  "system": {
    "seed": 1234,
    "log_level": "INFO",
    "device": "auto"
  }
}