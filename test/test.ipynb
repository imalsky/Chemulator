{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The provided filename /Users/imalsky/Desktop/Chemulator/data/trained_model_final_mlp/best_model_jit.pt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# --- Load Model, Metadata, and Test Set list ---\u001b[39;00m\n\u001b[1;32m     30\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model_jit.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (normalized_data_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalization_metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages/torch/jit/_serialization.py:158\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(f):\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided filename \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(f):\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided filename \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The provided filename /Users/imalsky/Desktop/Chemulator/data/trained_model_final_mlp/best_model_jit.pt does not exist"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add project source to path\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "from normalizer import DataNormalizer\n",
    "from utils import load_config\n",
    "\n",
    "plt.style.use('science.mplstyle')\n",
    "\n",
    "# %%\n",
    "# 2. LOAD ARTIFACTS\n",
    "# --- Paths ---\n",
    "CONFIG_FILE = project_root / \"inputs/model_input_params.jsonc\"\n",
    "DATA_ROOT = project_root / \"data\"\n",
    "config = load_config(CONFIG_FILE)\n",
    "model_folder = DATA_ROOT / config[\"output_paths_config\"][\"fixed_model_foldername\"]\n",
    "normalized_data_folder = DATA_ROOT / config[\"data_paths_config\"][\"normalized_profiles_foldername\"]\n",
    "raw_data_folder = DATA_ROOT / config[\"data_paths_config\"][\"raw_profiles_foldername\"]\n",
    "\n",
    "# --- Load Model, Metadata, and Test Set list ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.jit.load(model_folder / \"best_model_jit.pt\", map_location=device)\n",
    "model.eval()\n",
    "with (normalized_data_folder / \"normalization_metadata.json\").open(\"r\") as f:\n",
    "    norm_metadata = json.load(f)\n",
    "with (model_folder / \"test_set_info.json\").open(\"r\") as f:\n",
    "    test_filenames = json.load(f)[\"test_filenames\"]\n",
    "\n",
    "# --- Get variable lists from config ---\n",
    "species_vars = sorted(config[\"species_variables\"])\n",
    "global_vars = sorted(config[\"global_variables\"])\n",
    "species_labels = [s.replace('_evolution', '') for s in species_vars]\n",
    "\n",
    "print(f\"âœ… Setup complete. Model loaded on {device}.\")\n",
    "\n",
    "# %%\n",
    "# 3. PREDICT AND PLOT FOR A SINGLE TEST PROFILE\n",
    "\n",
    "# --- Select a random test file and load both versions ---\n",
    "test_filename = random.choice(test_filenames)\n",
    "with (normalized_data_folder / test_filename).open(\"r\") as f:\n",
    "    norm_profile = json.load(f)\n",
    "with (raw_data_folder / test_filename).open(\"r\") as f:\n",
    "    raw_profile = json.load(f)\n",
    "\n",
    "# --- Prepare the constant part of the input vector ---\n",
    "initial_species = [norm_profile[key][0] for key in species_vars]\n",
    "global_conds = [norm_profile[key] for key in global_vars]\n",
    "base_input = torch.tensor(initial_species + global_conds, dtype=torch.float32)\n",
    "\n",
    "# --- Predict for every time step in the profile ---\n",
    "predicted_evolutions_norm = [] # Store the normalized predictions first\n",
    "for norm_time_step in norm_profile[\"t_time\"]:\n",
    "    # Create the full input vector for this time step\n",
    "    input_vector = torch.cat([base_input, torch.tensor([norm_time_step])]).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        norm_pred = model(input_vector).cpu().squeeze(0)\n",
    "        predicted_evolutions_norm.append(norm_pred)\n",
    "\n",
    "# --- Stack and Denormalize All Predictions at Once ---\n",
    "# 1. Stack the list of 1D tensors into a 2D tensor of shape (num_timesteps, num_species)\n",
    "predicted_evolutions_norm = torch.stack(predicted_evolutions_norm)\n",
    "\n",
    "# 2. Transpose it to get shape (num_species, num_timesteps) for easier iteration\n",
    "predicted_evolutions_norm = predicted_evolutions_norm.T\n",
    "\n",
    "# 3. Denormalize each species' full time-series vector in one go. This is the fix.\n",
    "predicted_evolutions_denorm = []\n",
    "for i, key in enumerate(species_vars):\n",
    "    # Pass the entire time-series tensor for one species to denormalize\n",
    "    series_tensor = predicted_evolutions_norm[i]\n",
    "    denorm_series = DataNormalizer.denormalize(series_tensor, norm_metadata, key)\n",
    "    predicted_evolutions_denorm.append(denorm_series.numpy()) # Convert to numpy for plotting\n",
    "\n",
    "# predicted_evolutions_denorm is now a list of numpy arrays, ready for plotting.\n",
    "raw_times = raw_profile['t_time']\n",
    "\n",
    "# --- Plot the results ---\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(species_vars)))\n",
    "\n",
    "for i, key in enumerate(species_vars):\n",
    "    # Plot true evolution from raw data\n",
    "    ax.plot(raw_times, raw_profile[key], color=colors[i], label=species_labels[i] + \" (True)\")\n",
    "    # Plot predicted evolution (denormalized)\n",
    "    ax.scatter(raw_times, predicted_evolutions_denorm[i], color=colors[i], marker='x', s=30) # Changed marker for visibility\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Time (s)\", fontsize=14)\n",
    "ax.set_ylabel(\"Species Abundance\", fontsize=14)\n",
    "ax.set_title(f\"Predicted vs. True Species Evolution for {test_filename}\", fontsize=16)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.set_ylim(1e-9, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                                 Initialization                                 \n",
      "================================================================================\n",
      "Loading model and configuration artifacts...\n",
      "Setup complete. Model loaded on device: CPU\n",
      "\n",
      "================================================================================\n",
      "                             Performance Benchmark                             \n",
      "================================================================================\n",
      "Batch Size:                  512\n",
      "Device:                      CPU\n",
      "Average time per batch:      1.2045 ms\n",
      "Average time per single pred: 2.3526 Âµs (microseconds)\n",
      "\n",
      "================================================================================\n",
      "                          Single Prediction Validation                          \n",
      "================================================================================\n",
      "  - Using profile: prof_71020.json\n",
      "  - Predicting at time index 22 (t â‰ˆ 8.8862e+00 s)\n",
      "\n",
      "Species  Predicted Value  True Value  Abs. Error  Rel. Error (%)\n",
      "   C2H2       5.0318e-03  4.8384e-03  1.9345e-04      3.9983e+00\n",
      "    CH4       6.2143e-04  5.4206e-04  7.9377e-05      1.4644e+01\n",
      "    CO2       5.6723e-05  5.1188e-05  5.5355e-06      1.0814e+01\n",
      "     CO       1.0783e-05  1.0757e-05  2.6513e-08      2.4647e-01\n",
      "    H2O       1.3105e-02  1.3226e-02  1.2047e-04      9.1086e-01\n",
      "     H2       9.7524e-01  9.7083e-01  4.4080e-03      4.5404e-01\n",
      "    HCN       9.1030e-06  9.0634e-06  3.9583e-08      4.3673e-01\n",
      "      H       9.0387e-05  9.0863e-05  4.7662e-07      5.2455e-01\n",
      "     N2       2.8722e-03  3.1175e-03  2.4533e-04      7.8696e+00\n",
      "    NH3       7.9094e-03  7.2762e-03  6.3326e-04      8.7032e+00\n",
      "     OH       6.5342e-08  6.4664e-08  6.7794e-10      1.0484e+00\n",
      "      O       1.0086e-09  1.0000e-09  8.6363e-12      8.6363e-01\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Setup: Add project source to the Python path ---\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    \n",
    "from utils import load_config\n",
    "from normalizer import DataNormalizer\n",
    "\n",
    "def print_header(title: str):\n",
    "    \"\"\"Prints a formatted, centered header to the console.\"\"\"\n",
    "    width = 80\n",
    "    padding = (width - len(title) - 2) // 2\n",
    "    print(\"\\n\" + \"=\" * width)\n",
    "    print(\" \" * padding, title, \" \" * padding)\n",
    "    print(\"=\" * width)\n",
    "\n",
    "def prepare_batch_for_benchmark(batch_size: int, test_filenames: list, norm_data_folder: Path, species_vars: list, global_vars: list, device: torch.device):\n",
    "    \"\"\"\n",
    "    Creates a batch of input tensors for benchmarking.\n",
    "    Each item corresponds to the final time step of a randomly chosen test profile.\n",
    "    \"\"\"\n",
    "    batch_inputs = []\n",
    "    for _ in range(batch_size):\n",
    "        test_filename = random.choice(test_filenames)\n",
    "        with (norm_data_folder / test_filename).open(\"r\") as f:\n",
    "            norm_profile = json.load(f)\n",
    "        initial_species = [norm_profile[key][0] for key in species_vars]\n",
    "        global_conds = [norm_profile[key] for key in global_vars]\n",
    "        final_norm_time = norm_profile[\"t_time\"][-1]\n",
    "        input_vector = torch.tensor(initial_species + global_conds + [final_norm_time], dtype=torch.float32)\n",
    "        batch_inputs.append(input_vector)\n",
    "    return torch.stack(batch_inputs).to(device)\n",
    "\n",
    "\n",
    "def run_benchmark_and_validate():\n",
    "    \"\"\"\n",
    "    Main function to load artifacts, run a performance benchmark, and then\n",
    "    validate a single prediction with detailed output.\n",
    "    \"\"\"\n",
    "    # 1. LOAD ARTIFACTS\n",
    "    # --------------------------------------------------------------------------\n",
    "    print_header(\"Initialization\")\n",
    "    print(\"Loading model and configuration artifacts...\")\n",
    "    CONFIG_FILE = project_root / \"inputs/model_input_params.jsonc\"\n",
    "    DATA_ROOT = project_root / \"data\"\n",
    "    \n",
    "    config = load_config(CONFIG_FILE)\n",
    "    if not config: print(\"Error: Could not load configuration. Exiting.\"); return\n",
    "        \n",
    "    model_folder = DATA_ROOT / config[\"output_paths_config\"][\"fixed_model_foldername\"]\n",
    "    normalized_data_folder = DATA_ROOT / config[\"data_paths_config\"][\"normalized_profiles_foldername\"]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_path = model_folder / \"best_model_jit.pt\"\n",
    "    if not model_path.exists(): print(f\"Error: Model file not found at {model_path}. Exiting.\"); return\n",
    "\n",
    "    model = torch.jit.load(model_path, map_location=device)\n",
    "    model.eval()\n",
    "    \n",
    "    norm_meta_path = normalized_data_folder / \"normalization_metadata.json\"\n",
    "    if not norm_meta_path.exists(): print(f\"Error: Normalization metadata not found at {norm_meta_path}. Exiting.\"); return\n",
    "    with norm_meta_path.open(\"r\") as f:\n",
    "        norm_metadata = json.load(f)\n",
    "\n",
    "    test_info_path = model_folder / \"test_set_info.json\"\n",
    "    if not test_info_path.exists(): print(f\"Error: Test set info file not found at {test_info_path}. Exiting.\"); return\n",
    "    with test_info_path.open(\"r\") as f:\n",
    "        test_filenames = json.load(f)[\"test_filenames\"]\n",
    "\n",
    "    species_vars = sorted(config[\"species_variables\"])\n",
    "    global_vars = sorted(config[\"global_variables\"])\n",
    "    print(f\"Setup complete. Model loaded on device: {device.type.upper()}\")\n",
    "    \n",
    "    # 2. RUN PERFORMANCE BENCHMARK\n",
    "    # --------------------------------------------------------------------------\n",
    "    print_header(\"Performance Benchmark\")\n",
    "    BATCH_SIZE = 512\n",
    "    NUM_WARMUP_RUNS = 5\n",
    "    NUM_TIMING_RUNS = 20\n",
    "\n",
    "    batch_tensor = prepare_batch_for_benchmark(BATCH_SIZE, test_filenames, normalized_data_folder, species_vars, global_vars, device)\n",
    "    \n",
    "    # --- GPU Warmup ---\n",
    "    with torch.no_grad():\n",
    "        for _ in range(NUM_WARMUP_RUNS):\n",
    "            _ = model(batch_tensor)\n",
    "    if device.type == 'cuda': torch.cuda.synchronize()\n",
    "\n",
    "    # --- Timed Runs ---\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(NUM_TIMING_RUNS):\n",
    "            start_time = time.perf_counter()\n",
    "            _ = model(batch_tensor)\n",
    "            if device.type == 'cuda': torch.cuda.synchronize()\n",
    "            end_time = time.perf_counter()\n",
    "            timings.append(end_time - start_time)\n",
    "\n",
    "    # 3. REPORT BENCHMARK RESULTS\n",
    "    # --------------------------------------------------------------------------\n",
    "    total_time = sum(timings)\n",
    "    avg_batch_time_ms = (total_time / NUM_TIMING_RUNS) * 1000\n",
    "    avg_prediction_time_us = (avg_batch_time_ms / BATCH_SIZE) * 1000\n",
    "\n",
    "    print(f\"{'Batch Size:':<28} {BATCH_SIZE}\")\n",
    "    print(f\"{'Device:':<28} {device.type.upper()}\")\n",
    "    print(f\"{'Average time per batch:':<28} {avg_batch_time_ms:.4f} ms\")\n",
    "    print(f\"{'Average time per single pred:':<28} {avg_prediction_time_us:.4f} Âµs (microseconds)\")\n",
    "\n",
    "    # 4. RUN SINGLE PREDICTION VALIDATION\n",
    "    # --------------------------------------------------------------------------\n",
    "    print_header(\"Single Prediction Validation\")\n",
    "    test_filename = random.choice(test_filenames)\n",
    "    print(f\"  - Using profile: {test_filename}\")\n",
    "    with (normalized_data_folder / test_filename).open(\"r\") as f:\n",
    "        norm_profile = json.load(f)\n",
    "        \n",
    "    query_time_idx = random.randint(1, len(norm_profile[\"t_time\"]) - 1)\n",
    "    norm_time_to_predict = norm_profile[\"t_time\"][query_time_idx]\n",
    "    real_time_to_predict = DataNormalizer.denormalize(norm_time_to_predict, norm_metadata, \"t_time\")\n",
    "    print(f\"  - Predicting at time index {query_time_idx} (t â‰ˆ {real_time_to_predict:.4e} s)\")\n",
    "    \n",
    "    initial_species = [norm_profile[key][0] for key in species_vars]\n",
    "    global_conds = [norm_profile[key] for key in global_vars]\n",
    "    input_vector = torch.tensor(\n",
    "        initial_species + global_conds + [norm_time_to_predict], dtype=torch.float32\n",
    "    ).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        norm_prediction_tensor = model(input_vector).squeeze(0).cpu()\n",
    "\n",
    "    norm_true_values_tensor = torch.tensor([norm_profile[key][query_time_idx] for key in species_vars])\n",
    "    \n",
    "    # 5. DENORMALIZE AND REPORT VALIDATION RESULTS\n",
    "    # --------------------------------------------------------------------------\n",
    "    results = []\n",
    "    for i, key in enumerate(species_vars):\n",
    "        # Use .item() to extract the scalar value from the 0-dim tensor\n",
    "        predicted_val = DataNormalizer.denormalize(norm_prediction_tensor[i], norm_metadata, key).item()\n",
    "        true_val = DataNormalizer.denormalize(norm_true_values_tensor[i], norm_metadata, key).item()\n",
    "        \n",
    "        results.append({\n",
    "            \"Species\": key.replace('_evolution', ''),\n",
    "            \"Predicted Value\": predicted_val,\n",
    "            \"True Value\": true_val,\n",
    "            \"Abs. Error\": abs(predicted_val - true_val),\n",
    "            \"Rel. Error (%)\": abs(predicted_val - true_val) / (true_val + 1e-20) * 100\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Configure pandas for clean, aligned output\n",
    "    pd.options.display.float_format = '{:,.4e}'.format\n",
    "    \n",
    "    print(\"\\n\" + df.to_string(index=False))\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_benchmark_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
