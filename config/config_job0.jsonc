{
  "data": {
    "global_variables": [
      "P",
      "T"
    ],
    "species_variables": [],
    "target_species": [],
    "time_variable": "t_time"
  },

  "dataset": {
    "assume_shared_grid": true,

    // IMPORTANT (rollout stability):
    // In rollout mode the dataset returns K targets and *incremental* dt values:
    //   dt[0] = t[j0] - t[i]
    //   dt[k] = t[jk] - t[j{k-1}]  (k>0)
    //
    // If you want a true step-by-step 90-step rollout (no skipping dt points),
    // force the ONLY possible offset set by making the available offset count == K:
    //   K = times_per_anchor = 90
    //   min_steps = 1
    //   max_steps = 90
    "multi_time_per_anchor": true,
    "times_per_anchor": 90,

    // Long rollouts multiply compute. If 4096 OOMs or is too slow, lower it and
    // raise training.accumulate_grad_batches instead to keep effective batch size.
    "batch_size_train": 2048,

    "dt_epsilon": 1e-30,
    "mmap_mode": "r",

    "num_workers": 4,
    "persistent_workers": true,
    "pin_memory": true,
    "prefetch_factor": 2,

    // Keep false unless the entire processed dataset fits comfortably in VRAM.
    "preload_to_gpu": false,

    // When offsets are forced to 1..K (by max_steps-min_steps+1==K), this is irrelevant,
    // but leaving it true avoids per-sample dt schedules if you later loosen max_steps.
    "share_times_across_batch": true,

    "skip_scan": true,
    "skip_validate_grids": true,
    "storage_dtype": "float32",
    "use_first_anchor": true
  },

  "mixed_precision": {
    "mode": "bf16"
  },

  "model": {
    "activation": "silu",

    // MLP-only path (as you had it)
    "mlp_only": true,
    "mlp_hidden": [
      2048,
      2048,
      2048,
      2048,
      2048,
      2048
    ],

    // Residual prediction in z-space is the most stable default for long AR rollouts here.
    "predict_delta": true,
    "predict_delta_log_phys": false,

    // Unused when mlp_only=true (kept for compatibility with the same model.py)
    "dropout": 0.0,
    "latent_dim": 512,
    "encoder_hidden": [512, 512],
    "dynamics_hidden": [512, 512],
    "decoder_hidden": [512, 512],
    "dynamics_residual": true
  },

  "normalization": {
    "default_method": "log-standard",
    "epsilon": 1e-30,
    "min_std": 1e-10,
    "methods": {
      "P": "log-min-max",
      "T": "standard",
      "dt": "log-min-max",
      "t_time": "log-min-max"
    }
  },

  "paths": {
    "overwrite": false,
    "processed_data_dir": "data/processed",
    "raw_data_files": [],
    "work_dir": "models/mlp_rollout90_pf_legacy"
  },

  "preprocessing": {
    "hdf5_chunk_size": 0,
    "min_value_threshold": 1e-30,
    "npz_compressed": false,
    "num_workers": 32,
    "overwrite_data": false,
    "skip_first_timestep": false,
    "trajectories_per_shard": 65536
  },

  "system": {
    "cudnn_benchmark": true,
    "deterministic": false,
    "dtype": "float32",
    "io_dtype": "float32",
    "omp_num_threads": 4,
    "seed": 42,
    "tf32": true
  },

  "training": {
    // With batch_size_train=1024, accumulate=4 gives an effective batch ~4096.
    // Increase accumulate (or decrease batch_size_train) if you hit OOM / instability.
    "accumulate_grad_batches": 1,

    "adaptive_stiff_loss": {
      "epsilon_phys": 1e-20,
      "lambda_phys": 1.0,
      "lambda_z": 0.25,
      "use_weighting": false,
      "w_max": 2.0,
      "w_min": 0.5,
      "weight_power": 0.5
    },

    "auto_resume": true,
    "resume": null,

    "epochs": 100,
    "warmup_epochs": 10,

    "lr": 0.0003,
    "min_lr": 1e-07,
    "optimizer": "adamw",
    "weight_decay": 0.0001,

    // Keep clipping on; long rollouts amplify occasional outliers.
    "gradient_clip": 3.0,

    // These must be consistent with dataset.times_per_anchor (K) for rollout mode.
    // With min_steps=1, max_steps=90 => exactly 90 offsets exist => offsets are forced to 1..90
    // (i.e., true consecutive step-by-step rollout schedule).
    "min_steps": 1,
    "max_steps": 90,

    "pairs_per_traj": 2,

    "max_train_batches": 0,
    "max_val_batches": 0,

    "test_fraction": 0.1,
    "val_fraction": 0.1,
    "use_fraction": 1.0,

    "torch_compile": false,
    "torch_compile_backend": "inductor",
    "torch_compile_mode": "default",
    "compile_dynamic": false,
    "compile_fullgraph": false,

    "use_swa": false,
    "swa_epoch_start": 0.8,
    "swa_annealing_epochs": 10,
    "swa_annealing_strategy": "cos",

    "rollout": {
      "enabled": true,

      // Train on a genuinely long horizon (matches the “90-step” objective).
      "steps": 90,

      // Curriculum helps when the model collapses early in training on long horizons.
      // NOTE: dataset still provides K=90 targets; the trainer just uses the first N steps.
      "curriculum": {
        "enabled": true,
        "start_steps": 16,
        "end_steps": 90,
        "ramp_epochs": 20
      },

      // --- Temporal bundling options ---
      // Bundling trades compute for *less* true autoregressive depth during training.
      // If long-rollout stability is the main problem, do NOT bundle aggressively:
      //   - enabled=false  => true 90-step autoregressive recursion during training
      //   - enabled=true   => only steps/chunk_size recursive propagations
      "bundling": {
        "enabled": false,
        "chunk_size": 1
      },

      // --- Constraints applied at every propagated step ---
      // Helps prevent runaway drift in long rollouts.
      "clip": {
        "enabled": true,
        "log10_max": 0.0,
        "log10_min": -30.0
      },

      // --- Noise injection (train-time only) ---
      // Adds Gaussian noise in log10 space to the propagated state to encourage recovery.
      // NOTE: incompatible with pushforward.mode="paper", but compatible with "legacy".
      "noise": {
        "enabled": true,
        "log10_std": 0.01
      },

      // --- Loss weighting across time steps ---
      // Options:
      //   - "uniform": equal weight per step
      //   - "linear": later steps weighted more (targets long-horizon stability)
      //   - "exponential": weight[k] = (discount^k) / sum(...)
      "loss_weighting": "linear",
      "loss_discount": 0.99,

      // --- Truncated BPTT ---
      // If pushforward.enabled=true (below), you already avoid backprop-through-time by stop-grad,
      // so detach_every is mostly irrelevant.
      "detach_every": 0,

      // --- Pushforward / stop-grad training mode ---
      // This is the main stability knob in the original trainer for very long AR rollouts.
      // Options:
      //   - mode="legacy": detach the *input state* for steps > 0 (no BPTT), optional burn-in masking
      //   - mode="paper" : strict 2-chunk objective; requires steps == 2*chunk_size and burn_in_steps == chunk_size
      "pushforward": {
        "enabled": true,

        // Backward-compat knob (kept here explicitly). When burn_in_steps is present, this is ignored.
        "skip_first_step_loss": false,

        // burn_in_steps: first N steps get zero loss weight but are still propagated.
        // Setting this >0 directly emphasizes late-horizon stability.
        "burn_in_steps": 10,

        // Whether to apply pushforward behavior during validation rollout.
        // (Validation runs without grads; this mainly matters for consistency / backward-compat.)
        "apply_in_validation": true,

        "mode": "legacy",

        // Only used in mode="paper"
        "lambda_stability": 1.0
      },

      "validation": {
        "enabled": true,
        "steps": 90
      }
    }
  }
}
