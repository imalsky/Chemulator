{
    // ===== FILE PATHS =====
    "paths": {
        // Raw HDF5 data files to process
        "raw_data_files": [
            "data/raw/run9001-result.h5",
            "data/raw/run9002-result.h5",
            "data/raw/run9003-result.h5",
            "data/raw/run9004-result.h5",
            "data/raw/run9005-result.h5",
            "data/raw/run9006-result.h5",
            "data/raw/run9007-result.h5",
            "data/raw/run9008-result.h5",
            "data/raw/run9009-result.h5",
            "data/raw/run9010-result.h5"
        ],
        // Directory for processed NPY shards
        "processed_data_dir": "data/processed",
        // Directory for saved models
        "model_save_dir": "data/models",
        // Directory for logs
        "log_dir": "logs"
    },
    
    // ===== DATA CONFIGURATION =====
    "data": {
        // Chemical species to predict (order matters!)
        "species_variables": [
            "C2H2_evolution",
            "CH4_evolution",
            "CO2_evolution",
            "CO_evolution",
            "H2O_evolution",
            "H2_evolution",
            "HCN_evolution",
            "H_evolution",
            "N2_evolution",
            "NH3_evolution",
            "OH_evolution",
            "O_evolution"
        ],
        // Global parameters (initial conditions)
        "global_variables": ["P_init", "T_init"],
        // Time variable name in HDF5 files
        "time_variable": "t_time"
    },
    
    // ===== PREPROCESSING SETTINGS =====
    "preprocessing": {
        // Number of samples per NPY shard file
        "shard_size": 1000000,
        // Minimum species concentration threshold
        "min_value_threshold": 1e-25,
        // Compression type: null for raw npy files (faster I/O)
        "compression": null,
        // Number of parallel workers for preprocessing
        "num_workers": 24,
        // Enable parallel preprocessing
        "parallel_enabled": true
    },
    
    // ===== NORMALIZATION SETTINGS =====
    "normalization": {
        // Default normalization method for all variables
        "default_method": "log-min-max",
        
        // Override methods for specific variables
        "methods": {
            "T_init": "standard",
            "P_init": "log-min-max",
            "t_time": "log-min-max"
        },
        
        // Small value to prevent log(0) and division by zero
        "epsilon": 1e-30,
        // Minimum standard deviation to prevent division by tiny values
        "min_std": 1e-10,
        // Clamp normalized values to [-clamp_value, clamp_value]
        "clamp_value": 50.0
    },
    
    // ===== MODEL ARCHITECTURE =====
    "model": {
        // Model type: "deeponet" or "siren" (both work with absolute mode)
        "type": "deeponet",
        
        // Activation function: "gelu", "relu", "silu", "tanh"
        "activation": "gelu",
        
        // Dropout rate (0.0 = no dropout)
        "dropout": 0.0,
        
        // Output scaling factor (1.0 = no scaling)
        "output_scale": 1.0,
        
        // DeepONet-specific parameters
        "branch_layers": [256, 256, 256],
        "trunk_layers": [128, 128],
        "basis_dim": 128,
        
        // SIREN-specific parameters (when type="siren")
        "hidden_dims": [256, 256, 256],
        "omega_0": 30.0
    },
    
    // ===== FiLM CONDITIONING =====
    "film": {
        // Enable Feature-wise Linear Modulation
        "enabled": true,
        // Hidden layers for FiLM networks
        "hidden_dims": [64],
        // Activation for FiLM networks
        "activation": "gelu"
    },
    
    // ===== PREDICTION SETTINGS =====
    "prediction": {
        // Prediction mode: ABSOLUTE ONLY for this config
        "mode": "absolute",
        
        // Optional output clamping
        "output_clamp": null
    },
    
    // ===== TRAINING PARAMETERS =====
    "training": {
        // Data splitting
        "val_fraction": 0.15,
        "test_fraction": 0.15,
        "use_fraction": 1.0,
        
        // Training duration
        "epochs": 100,  // Full training epochs (not used in HPO)
        "batch_size": 4096,
        "gradient_accumulation_steps": 2,
        
        // MEMORY-OPTIMIZED DATALOADER SETTINGS
        "num_workers": 8,
        "pin_memory": true,
        "persistent_workers": true,
        "prefetch_factor": 4,
        "drop_last": true,
        "dataset_cache_shards": 32,
        
        // Learning rate and optimizer settings
        "learning_rate": 3e-4,  // Starting LR for HPO
        "weight_decay": 1e-5,
        "betas": [0.9, 0.999],
        "eps": 1e-8,
        "gradient_clip": 1.0,
        
        // Scheduler settings - CRITICAL FOR LR DECAY
        "scheduler": "cosine",
        "scheduler_params": {
            "T_0": 10,  // Restart every 8 epochs (5 cycles in 40 epochs)
            "T_mult": 2,  // Keep cycle length constant
            "eta_min": 1e-8  // ENSURES LR DROPS TO 1e-8
        },
        
        // Loss and training settings
        "loss": "mse",
        "huber_delta": 0.5,
        "use_amp": true,
        "amp_dtype": "bfloat16",
        "early_stopping_patience": 10,  // Stop if no improvement for 8 epochs
        "min_delta": 1e-8,
        "log_interval": 100,
        "save_interval": 10,
        "empty_cache_interval": 500,
        
        // HPO-specific settings
        "hpo_min_epochs": 10,  // Minimum epochs before pruning
        "hpo_max_epochs": 40   // Maximum epochs for best trials
    },
    
    // ===== SYSTEM/HARDWARE SETTINGS =====
    "system": {
        // Random seed for reproducibility
        "seed": 42,
        
        // PyTorch optimizations
        "use_torch_compile": false,
        "compile_mode": "default",
        "use_torch_export": false,
        
        // CUDA optimizations for A100
        "cudnn_benchmark": true,
        "tf32": true,
        "cuda_memory_fraction": 0.90
    },
    
    // ===== HYPERPARAMETER OPTIMIZATION =====
    "optuna": {
        // Enable Optuna integration
        "enabled": true,
        
        // Hyperband settings for 40-hour window
        "algorithm": "hyperband",
        "hyperband_min_resource": 10,  // 1.4 hours minimum
        "hyperband_max_resource": 40,  // 5.5 hours maximum
        "hyperband_reduction_factor": 3,  // Keep top 33% at each stage
        
        // Target number of trials for 40 hours
        "n_trials": 50  // Conservative estimate with pruning
    }
}