{
  // ===============================
  // PATHS
  // ===============================
  "paths": {
    "processed_data_dir": "data/processed",
    "work_dir": "models/stable-lpv-koopman",
    "raw_data_files": []
  },

  // ===============================
  // DATA SCHEMA
  // ===============================
  "data": {
    "species_variables": [],
    "global_variables": ["P", "T"],
    "time_variable": "t_time"
  },

  // ===============================
  // DATASET / DATALOADER
  // ===============================
  "dataset": {
    // Multi-time sampling per anchor
    "multi_time_per_anchor": true,
    "times_per_anchor": 16,
    "share_times_across_batch": true,

    // Log-uniform dt sampling
    "log_dt_sampling": true,
    "precompute_dt_table": true,

    // Grid validation (can skip for speed if data is trusted)
    "uniform_grid_rtol": 1e-6,
    "uniform_grid_atol": 1e-12,
    "snap_shared_grid": true,
    "assume_shared_grid": true,
    "skip_scan": true,
    "skip_validate_grids": true,

    // Require dt stats in normalization manifest (fail if missing)
    "require_dt_stats": false,

    // Storage dtype for staged tensors
    "storage_dtype": "float32",

    // DataLoader settings
    "preload_train_to_gpu": false,
    "preload_val_to_gpu": false,
    "num_workers": 8,
    "num_workers_val": 8,
    "pin_memory": true,
    "pin_memory_val": true,
    "prefetch_factor": 2,
    "prefetch_factor_val": 2,
    "persistent_workers": true,
    "persistent_workers_val": true,

    "log_every_files": 1000
  },

  // ===============================
  // MODEL (Stable LPV Koopman AE)
  // ===============================
  "model": {
    "latent_dim": 64,
    "encoder_hidden": [512, 512, 512],
    "decoder_hidden": [512, 512, 512],
    "activation": "silu",
    "dropout": 0.0,

    // Decoder output options
    "softmax_head": false,
    "predict_delta": true,
    "z_std_clip": 10.0,

    // LPV dynamics conditioning
    "cond_hidden": [64, 64],
    "rank_l": 12,
    "use_S": false,
    "gamma": 0.10
  },

  // ===============================
  // TRAINING
  // ===============================
  "training": {
    // Batch sizes (must be explicit integers)
    "batch_size": 2048,
    "val_batch_size": 4096,

    // Trajectory pair sampling
    "pairs_per_traj": 16,
    "pairs_per_traj_val": 4,
    "min_steps": 1,
    "max_steps": 99,

    // Dataset splits (used by preprocessor)
    "val_fraction": 0.1,
    "test_fraction": 0.1,

    // Use only a fraction of data (helpful for debugging with smaller datasets)
    "use_fraction": 1.0,

    // Optimizer hyperparameters
    "lr": 1.0e-4,
    "min_lr": 1.0e-6,
    "weight_decay": 1.0e-3,
    "warmup_epochs": 10,
    "epochs": 100,

    // Gradient clipping (0.0 = disabled)
    "gradient_clip": 1.0,

    "loss": {
      "tail_huber": {
        "weight": 0.0,
        "delta": 0.02,
        "z_threshold": -1.0
      },
      "fractional": {
        "weight": 0.1,
        "eps": 1e-8
      }
    },

    // Auxiliary losses
    "auxiliary_losses": {
      // Rollout loss (autoregressive stability)
      "rollout_enabled": true,
      "rollout_weight": 0.5,
      "rollout_horizon": 4,
      "rollout_warmup_epochs": 10,
      // false = autoregressive (re-encodes each step, slower but safer)
      // true  = cached (encode once, faster, assumes model handles it)
      "rollout_use_cached_encoding": false,

      // Teacher forcing schedule for rollout
      "rollout_teacher_forcing": {
        "mode": "linear",
        "start_p": 1.0,
        "end_p": 0.2,
        "end_epoch": 60
      },

      // Semigroup consistency loss
      "semigroup_enabled": true,
      "semigroup_weight": 0.005,
      "semigroup_warmup_epochs": 10
    },

    // Resume controls (used by main.py)
    "resume": null,
    "auto_resume": false,

    // Debug short run
    "fast_dev_run": false
  },

  // ===============================
  // LIGHTNING RUNTIME
  // ===============================
  "lightning": {
    // Hardware
    "accelerator": "auto",
    "devices": 1,
    "precision": "bf16-mixed",

    // Training settings
    "accumulate_grad_batches": 1,

    // Strategy for multi-GPU (if devices > 1)
    "strategy": "auto",

    // Debugging flags
    "num_sanity_val_steps": 0
  },

  // ===============================
  // PREPROCESSING
  // ===============================
  "preprocessing": {
    "trajectories_per_shard": 4096,
    "npz_compressed": false,
    "min_value_threshold": 1e-30,
    "hdf5_chunk_size": 0,
    "num_workers": 0
  },

  // ===============================
  // NORMALIZATION
  // ===============================
  "normalization": {
    "default_method": "log-standard",
    "methods": {
      "t_time": "log-min-max",
      "dt": "log-min-max",
      "T": "standard",
      "P": "log-standard"
    },
    "epsilon": 1e-30,
    "min_std": 1e-10,
    "clamp_value": 1e-30
  },

  // ===============================
  // SYSTEM / HARDWARE
  // ===============================
  "system": {
    "seed": 42,
    "tf32": true,
    "cudnn_benchmark": true,
    "deterministic": false,
    "linalg_library": null,
    "omp_threads": null,
    "io_dtype": "float32"
  }
}