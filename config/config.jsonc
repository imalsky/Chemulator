{
    // ===== FILE PATHS =====
    "paths": {
        // Raw HDF5 data files to process
        "raw_data_files": [
            "data/raw/run9001-result.h5",
            "data/raw/run9002-result.h5",
            "data/raw/run9003-result.h5",
            "data/raw/run9004-result.h5",
            "data/raw/run9005-result.h5",
            "data/raw/run9006-result.h5",
            "data/raw/run9007-result.h5",
            "data/raw/run9008-result.h5",
            "data/raw/run9009-result.h5",
            "data/raw/run9010-result.h5"
        ],
        // Directory for processed NPY shards
        "processed_data_dir": "data/processed",
        // Directory for saved models
        "model_save_dir": "data/models",
        // Directory for logs
        "log_dir": "logs"
    },
    
    // ===== DATA CONFIGURATION =====
    "data": {
        // Chemical species to predict (order matters!)
        "species_variables": [
            "C2H2_evolution",
            "CH4_evolution",
            "CO2_evolution",
            "CO_evolution",
            "H2O_evolution",
            "H2_evolution",
            "HCN_evolution",
            "H_evolution",
            "N2_evolution",
            "NH3_evolution",
            "OH_evolution",
            "O_evolution"
        ],
        // Global parameters (initial conditions)
        "global_variables": ["P_init", "T_init"],
        // Time variable name in HDF5 files
        "time_variable": "t_time"
    },
    
    // ===== PREPROCESSING SETTINGS =====
    "preprocessing": {
        // Number of samples per NPY shard file
        "shard_size": 10000000,
        // Minimum species concentration threshold
        "min_value_threshold": 1e-25,
        // Compression type: null for raw npy files (faster I/O)
        "compression": null,
        // Number of parallel workers for preprocessing
        "num_workers": 4,
        // Enable parallel preprocessing
        "parallel_enabled": true
    },
    
    // ===== NORMALIZATION SETTINGS =====
    "normalization": {
        // Default normalization method for all variables
        "default_method": "log-min-max",
        
        // Override methods for specific variables
        "methods": {
            "T_init": "standard",
            "P_init": "log-min-max",
            "t_time": "log-min-max"
        },
        
        // This needs to be fixed
        "epsilon": 1e-38,
        // Minimum standard deviation to prevent division by tiny values
        "min_std": 1e-10,
        // Clamp normalized values to [-clamp_value, clamp_value]
        "clamp_value": 50.0
    },
    
    // ===== MODEL ARCHITECTURE =====
    "model": {
        // Model type: "deeponet" or "siren" (both work with absolute mode)
        "type": "siren",
        
        // Activation function: "gelu", "relu", "silu", "tanh"
        "activation": "gelu",
        
        // Dropout rate (0.0 = no dropout)
        "dropout": 0.0,
        
        // Output scaling factor (1.0 = no scaling)
        "output_scale": 1.0,
        
        // DeepONet-specific parameters
        "branch_layers": [512, 512, 512, 512],
        "trunk_layers": [64, 64, 64, 64],
        "basis_dim": 32,
        
        // SIREN-specific parameters (when type="siren")
        "hidden_dims": [512, 512, 512, 512],
        "omega_0": 30.0
    },
    
    // ===== FiLM CONDITIONING =====
    "film": {
        // Enable Feature-wise Linear Modulation
        "enabled": true,
        // Hidden layers for FiLM networks
        "hidden_dims": [64, 64, 64, 64],
        // Activation for FiLM networks (can be string or list)
        "activation": "gelu"
        // For per-layer activations use: "activations": ["gelu", "relu", "silu", "gelu"]
    },
    
    // ===== PREDICTION SETTINGS =====
    "prediction": {
        // Prediction mode: ABSOLUTE ONLY for this config
        // ratio mode is still in progress
        "mode": "absolute",
        
        // Optional output clamping
        "output_clamp": null
    },
    
    // ===== TRAINING PARAMETERS =====
    "training": {
        // Data splitting
        "val_fraction": 0.15,
        "test_fraction": 0.15,
        "use_fraction": 1.0,
        
        // Training duration
        "epochs": 50,
        
        // BATCH SIZE - Increase for GPU mode
        "batch_size": 16384,  // Use 65536 or higher on A100
        "gradient_accumulation_steps": 1,
        
        // GPU CACHING SETTINGS (NEW)
        // Options: "auto" (default), true, false
        // "auto" = use GPU cache if enough memory available
        "gpu_cache_dataset": "auto",
        
        // DATALOADER SETTINGS - Adjust based on mode
        // For GPU mode: set num_workers=0
        // For CPU mode: set num_workers=4-8
        "num_workers": 4,
        "pin_memory": true,
        "persistent_workers": true,
        "prefetch_factor": 2,
        "drop_last": true,
        "dataset_cache_shards": 64,  // Only used in CPU mode
        
        // Learning rate and optimizer settings
        "learning_rate": 5e-4,
        "weight_decay": 1e-5,
        "betas": [0.9, 0.999],
        "eps": 1e-8,
        "gradient_clip": 1.0,
        
        // Scheduler settings
        "scheduler": "cosine",
        "scheduler_params": {
            "T_0": 50,
            "T_mult": 2,
            "eta_min": 1e-8
        },
        
        // Loss and training settings
        "loss": "mse",
        "huber_delta": 0.5,
        "use_amp": true,
        "amp_dtype": "bfloat16",
        "early_stopping_patience": 10,
        "min_delta": 1e-8,
        "log_interval": 100,
        "save_interval": 10,
        "empty_cache_interval": 500,
        
        // HPO-specific settings
        "hpo_min_epochs": 10,
        "hpo_max_epochs": 40
    },
    
    // ===== SYSTEM/HARDWARE SETTINGS =====
    "system": {
        // Random seed for reproducibility
        "seed": 42,
        
        // PyTorch optimizations
        "use_torch_compile": true,
        "compile_mode": "default",
        "use_torch_export": true,
        
        // CUDA optimizations for A100
        "cudnn_benchmark": true,
        "tf32": true,
        "cuda_memory_fraction": 0.90
    },
    
    // ===== HYPERPARAMETER OPTIMIZATION =====
    "optuna": {
        // Enable Optuna integration
        "enabled": true,
        
        // Hyperband settings
        "algorithm": "hyperband",
        "hyperband_min_resource": 10,
        "hyperband_max_resource": 40,
        "hyperband_reduction_factor": 3,
        
        // Target number of trials
        "n_trials": 100
    }
}

// ===== CONFIGURATION PROFILES =====
// 
// FOR LOCAL MACHINE (CPU or small GPU):
// - Set batch_size: 1024-4096
// - Set num_workers: 2-4
// - Set dataset_cache_shards: 8-16
// - Set gpu_cache_dataset: false
// - Consider smaller model: hidden_dims: [128, 128, 128]
//
// FOR A100 GPU (High memory):
// - Set batch_size: 65536 or higher
// - Set num_workers: 0 (when using GPU cache)
// - Set gpu_cache_dataset: "auto" or true
// - Can use larger model: hidden_dims: [512, 512, 512, 512]
//
// GPU caching will automatically activate when:
// - gpu_cache_dataset is "auto" or true
// - Device is CUDA
// - Dataset fits in 80% of available GPU memory