{
  // AE-DeepONet Configuration File
  // Configured to use ALL available time points throughout the pipeline

  "paths": {
    // Input HDF5 files (produced by your simulator/export)
    "raw_data_files": [
      "data/raw/run9001-result.h5"
      // Add more files as needed
    ],
    // Directory containing preprocessed NPZ shards
    "processed_data_dir": "data/processed-1-log-standard",
    // Root folder for checkpoints
    "model_save_dir": "models",
    // Root folder for logs
    "log_dir": "logs"
  },

  "data": {
    // Species variables in the dataset
    "species_variables": [
      "C2H2_evolution", "CH4_evolution", "CO2_evolution", "CO_evolution",
      "H2O_evolution", "H2_evolution", "HCN_evolution", "H_evolution",
      "N2_evolution", "NH3_evolution", "OH_evolution", "O_evolution"
    ],
    // Target species (same as input for this case)
    "target_species_variables": [
      "C2H2_evolution", "CH4_evolution", "CO2_evolution", "CO_evolution",
      "H2O_evolution", "H2_evolution", "HCN_evolution", "H_evolution",
      "N2_evolution", "NH3_evolution", "OH_evolution", "O_evolution"
    ],
    // Global variables: [P, T]
    "global_variables": ["P", "T"],
    // Hard validation - must match
    "expected_globals": ["P", "T"],
    // Time variable name
    "time_variable": "t_time"
  },

  "preprocessing": {
    // Minimum value threshold for species concentrations
    "min_value_threshold": 1e-25,
    // Parallel workers for preprocessing
    "num_workers": 8,
    // HDF5 chunk size for reading
    "hdf5_chunk_size": 16384,
    // Trajectories per NPZ shard
    "trajectories_per_shard": 10000,
    // Use compression for NPZ files
    "npz_compressed": false
  },

  "normalization": {
    // Default normalization method for species
    "default_method": "log-standard",
    "methods": {
      // Time MUST be log-min-max for proper [0,1] scaling
      "t_time": "log-min-max",
      // Pressure uses log-standard (covers wide range)
      "P": "log-standard",
      // Temperature uses standard normalization
      "T": "standard"
    },
    // Epsilon for log transforms
    "epsilon": 1e-30,
    // Minimum std for numerical stability
    "min_std": 1e-10,
    // Clamp normalized values
    "clamp_value": 50.0
  },

  "model": {
    "type": "AE_DeepONet",
    // Latent dimension for autoencoder
    "latent_dim": 32,
    // DeepONet basis functions
    "p": 10,
    // Trunk basis type: "linear" or "softmax"
    "trunk_basis": "linear",
    // Enable PoU regularization for linear basis
    "use_pou": true,
    // Architecture: 3 hidden layers for each network
    "ae_encoder_layers": [256, 128, 64],
    "ae_decoder_layers": [64, 128, 256],
    "branch_layers": [256, 128, 64],
    "trunk_layers": [256, 128, 64],
    // Decoder output mode
    "decoder_output_mode": "linear",
    // No clamping in normalized space
    "output_clamp": null
  },

  // ============================================================================
  // LATENT DATASET GENERATION
  // ============================================================================

  "latent_generation": {
    // AVAILABLE OPTIONS: "fixed" | "all"
    // Using "all" - encode every time point from source data
    "mode": "all"

    // When mode="all":
    // - Uses entire source time grid (no selection/subsampling)
    // - All trajectories MUST have identical time grids
    // - Significantly increases memory usage
    // - No additional parameters needed

    // Alternative mode="fixed" would require:
    // "fixed_times": [0.1, 0.2, ...] // specific normalized times to extract
  },

  // ============================================================================
  // TRAINING CONFIGURATION
  // ============================================================================

  "training": {
    // Stage 1: Autoencoder pretraining
    "ae_per_trajectory": true,
    "ae_pretrain_epochs": 100,
    "ae_warmup_epochs": 5,
    "freeze_ae_after_pretrain": true,

    // Stage 3: DeepONet training
    "epochs": 200,
    "batch_size": 1024,

    // ===== TRAINING TIME SAMPLING =====
    // AVAILABLE OPTIONS: "fixed" | "random"
    // Using "fixed" with "all" to use every available time point
    "train_time_sampling": "fixed",

    // For "fixed" sampling, options are:
    // - List of specific times: [0.1, 0.2, ...]
    // - String "all": use every point in latent dataset
    // - Not specified: use train_time_points count
    "train_fixed_times": "all",  // USE ALL AVAILABLE POINTS

    // Alternative configurations:
    // "train_fixed_times": [0.1, 0.5, 1.0],  // specific times only
    // "train_time_points": 50,  // evenly spaced count (if train_fixed_times not set)

    // Alternative "random" sampling would use:
    // "train_time_sampling": "random",
    // "train_min_time_points": 8,
    // "train_max_time_points": 32,

    // ===== VALIDATION TIME SAMPLING =====
    // AVAILABLE OPTIONS: "fixed" | "random"
    // Using "fixed" with "all" for comprehensive validation
    "val_time_sampling": "fixed",
    "val_fixed_times": "all",  // USE ALL AVAILABLE POINTS

    // Alternative configurations:
    // "val_fixed_times": [0.1, 0.5, 1.0],  // specific times only
    // "val_time_points": 50,  // evenly spaced count (if val_fixed_times not set)

    // Learning rate schedule
    "learning_rate": 1e-3,
    "min_lr": 1e-6,
    "warmup_epochs": 10,

    // Data splits
    "val_fraction": 0.15,
    "test_fraction": 0.15,
    "use_fraction": 1.0,

    // AdamW optimizer settings
    "weight_decay": 1e-4,
    "betas": [0.9, 0.999],

    // Training stability
    "gradient_clip": 1.0,
    "use_amp": true,

    // PoU regularization weight
    "pou_weight": 0.01,

    // Dataloader workers (forced to 0 for GPU datasets)
    "num_workers": 0
  },

  "system": {
    // Random seed for reproducibility
    "seed": 42,
    // Export model for deployment
    "use_torch_export": true,
    // Use torch.compile for potential speedup
    "use_torch_compile": true,
    "compile_mode": "default",
    // CUDA optimizations
    "cudnn_benchmark": true,
    "tf32": true,
    "cuda_memory_fraction": 0.95,
    // Non-deterministic for speed
    "deterministic": false,
    // Default precision
    "dtype": "float32"
  }
}