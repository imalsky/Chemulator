{
  "paths": {
    "raw_data_files": [
      "data/raw/run9001-result.h5",
      "data/raw/run9002-result.h5",
      "data/raw/run9003-result.h5",
      "data/raw/run9004-result.h5",
      "data/raw/run9005-result.h5",
      "data/raw/run9006-result.h5",
      "data/raw/run9007-result.h5",
      "data/raw/run9008-result.h5",
      "data/raw/run9009-result.h5",
      "data/raw/run9010-result.h5"
    ],
    "processed_data_dir": "data/processed-10-log-standard",
    "model_save_dir": "models",
    "log_dir": "logs"
  },

  "data": {
    // Variables in HDF5 files - used during preprocessing
    "species_variables": [
      "C2H2_evolution", "CH4_evolution", "CO2_evolution", "CO_evolution",
      "H2O_evolution", "H2_evolution", "HCN_evolution", "H_evolution",
      "N2_evolution", "NH3_evolution", "OH_evolution", "O_evolution"
    ],
    // Target species for output - usually same as species_variables
    "target_species_variables": [
      "C2H2_evolution", "CH4_evolution", "CO2_evolution", "CO_evolution",
      "H2O_evolution", "H2_evolution", "HCN_evolution", "H_evolution",
      "N2_evolution", "NH3_evolution", "OH_evolution", "O_evolution"
    ],
    // Global conditioning variables: [P, T] not paper's [φ₀, T₀]
    "global_variables": ["P", "T"],
    "expected_globals": ["P", "T"],  // Validation check
    "time_variable": "t_time"  // Name of time array in HDF5
  },

  "preprocessing": {
    "min_value_threshold": 1e-25,  // Drop trajectories below this
    "num_workers": 8,  // Parallel processing
    "trajectories_per_shard": 10000,  // NPZ file size control
    "npz_compressed": false  // Faster I/O without compression
  },

  "normalization": {
    // Applied during preprocessing and data loading
    "default_method": "log-standard",  // For species
    "methods": {
      "t_time": "log-min-max",  // Maps time to [0,1] - REQUIRED
      "P": "log-standard",      // Pressure normalization
      "T": "standard"            // Temperature normalization
    },
    "epsilon": 1e-30,  // Floor for log transform
    "min_std": 1e-10   // Numerical stability
  },

  "model": {
    "type": "AE_DeepONet",

    // Autoencoder settings (Stage 1)
    "latent_dim": 16,  // Compression dimension
    "ae_encoder_layers": [256, 256, 128],
    "ae_decoder_layers": [128, 256, 256],

    // DeepONet settings (Stage 3)
    "p": 10,  // Number of basis functions
    "branch_layers": [256, 256, 128],
    "trunk_layers": [256, 256, 128],

    // THE ONLY TIME SPECIFICATION NEEDED
    // Used for: 1) Default inference times
    //           2) Fallback for latent generation if not specified
    //           3) Fallback for training if not specified
    "trunk_times": [0.25, 0.50, 0.75, 1.0],

    // Basis and regularization
    "trunk_basis": "linear",  // or "softmax"
    "use_pou": true,  // Partition of Unity regularization

    // Output configuration
    "decoder_output_mode": "linear",
    "output_clamp": null  // No clamping in normalized space
  },

  "latent_generation": {
    // Stage 2: Generate latent dataset
    // "fixed" mode uses nearest-neighbor from source grid
    // "all" mode uses all available time points (requires identical grids)
    // No fixed_times specified - uses model.trunk_times
    "mode": "fixed"
  },

  "training": {
    // Stage 1: Autoencoder pretraining
    "ae_pretrain_epochs": 50,
    "ae_warmup_epochs": 0,
    "freeze_ae_after_pretrain": true,

    // Stage 3: DeepONet training
    "epochs": 200,
    "batch_size": 512,

    // Time sampling strategy
    // "fixed": All samples use same time points (vectorized, fast)
    // "random": Each sample picks random subset (requires padding, slower)
    "train_time_sampling": "fixed",
    "val_time_sampling": "fixed",

    // Optional: Specify subset of available times
    // If not specified, uses all available latent times
    // "train_time_points": 5,  // Would use first 5 of trunk_times
    // "val_time_points": 10,   // Would use all 10

    // Learning rate schedule
    "learning_rate": 1e-3,
    "min_lr": 1e-6,
    "warmup_epochs": 10,

    // Data splits - applied deterministically during preprocessing
    "val_fraction": 0.15,
    "test_fraction": 0.15,
    "use_fraction": 1.0,  // Subsample data if < 1.0

    // Optimizer (AdamW)
    "weight_decay": 1e-4,
    "betas": [0.9, 0.999],

    // Training stability
    "gradient_clip": 1.0,
    "use_amp": true,  // Mixed precision for speed/memory

    // PoU regularization weight
    "pou_weight": 0.01,

    // DataLoader settings
    "num_workers": 0  // Must be 0 for GPU-resident datasets
  },

  "system": {
    "seed": 42,  // Reproducibility
    "use_torch_export": true,  // Export for deployment
    "use_torch_compile": false,  // Often fails with dynamic shapes
    "cudnn_benchmark": true,  // Auto-tune convolutions
    "tf32": true,  // Use TensorFloat32 for speed
    "cuda_memory_fraction": 0.95,  // Reserve GPU memory
    "deterministic": false,  // Trade reproducibility for speed
    "dtype": "float32"  // Model precision
  }
}