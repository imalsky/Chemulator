{
    // ===== OPTIMIZED CONFIGURATION FOR A100 GPU =====
    // This configuration maximizes performance on NVIDIA A100 80GB
    
    // ===== FILE PATHS =====
    "paths": {
        // Raw HDF5 data files to process
        "raw_data_files": [
            "data/raw/run9001-result.h5",
            "data/raw/run9002-result.h5",
            "data/raw/run9003-result.h5",
            "data/raw/run9004-result.h5",
            "data/raw/run9005-result.h5",
            "data/raw/run9006-result.h5",
            "data/raw/run9007-result.h5",
            "data/raw/run9008-result.h5",
            "data/raw/run9009-result.h5",
            "data/raw/run9010-result.h5"
        ],
        // Directory for processed NPY shards
        "processed_data_dir": "data/processed",
        // Directory for saved models
        "model_save_dir": "data/models",
        // Directory for logs
        "log_dir": "logs"
    },
    
    // ===== DATA CONFIGURATION =====
    "data": {
        // Chemical species to predict (order matters!)
        "species_variables": [
            "C2H2_evolution",
            "CH4_evolution",
            "CO2_evolution",
            "CO_evolution",
            "H2O_evolution",
            "H2_evolution",
            "HCN_evolution",
            "H_evolution",
            "N2_evolution",
            "NH3_evolution",
            "OH_evolution",
            "O_evolution"
        ],
        "target_species_variables": ["NH3_evolution"],

        // Global parameters (initial conditions)
        "global_variables": ["P", "T"],
        // Time variable name in HDF5 files
        "time_variable": "t_time"
    },
    
    // ===== PREPROCESSING SETTINGS =====
    "preprocessing": {
        // Number of samples per NPY shard file
        "shard_size": 10000000,
        // Minimum species concentration threshold
        "min_value_threshold": 1e-25,
        // Compression type: null for raw npy files (faster I/O)
        "compression": null,
        // Number of parallel workers for preprocessing
        "num_workers": 8,
        // Enable parallel preprocessing
        "parallel_enabled": true
    },
    
    // ===== NORMALIZATION SETTINGS =====
    "normalization": {
        // Default normalization method for all variables
        "default_method": "log-standard",
        
        // Override methods for specific variables
        "methods": {
            "T_init": "standard",
            "P_init": "log-min-max",
            "t_time": "log-min-max"
        },
        
        // Epsilon for numerical stability
        "epsilon": 1e-38,
        // Minimum standard deviation to prevent division by tiny values
        "min_std": 1e-10,
        // Clamp normalized values to [-clamp_value, clamp_value]
        "clamp_value": 50.0
    },
    
    // ===== MODEL ARCHITECTURE =====
    "model": {
        // Model type: "deeponet" or "siren"
        "type": "deeponet",
        
        // Activation function: "gelu", "relu", "silu", "tanh"
        "activation": "gelu",
        
        // Dropout rate (0.0 = no dropout)
        "dropout": 0.1,
        
        // Output scaling factor (1.0 = no scaling)
        "output_scale": 1.0,
        
        // DeepONet-specific parameters
        "branch_layers": [384, 384, 384, 384],
        "trunk_layers": [128, 128, 128, 128],
        "basis_dim": 64,
        
        // SIREN-specific parameters (when type="siren")
        "hidden_dims": [256, 256, 256],
        "omega_0": 30.0
    },
    
    // ===== FiLM CONDITIONING =====
    "film": {
        // Enable Feature-wise Linear Modulation
        "enabled": true,
        // Hidden layers for FiLM networks
        "hidden_dims": [128, 128],
        // Activation for FiLM networks
        "activation": "relu"
    },
    
    // ===== PREDICTION SETTINGS =====
    "prediction": {
        // Prediction mode: "absolute" or "ratio"
        "mode": "absolute",
        
        // Optional output clamping
        "output_clamp": null
    },
    
    // ===== TRAINING PARAMETERS - OPTIMIZED FOR A100 =====
    "training": {
        // Data splitting
        "val_fraction": 0.15,
        "test_fraction": 0.15,
        "use_fraction": 1.0,
        
        // Training duration
        "epochs": 50,
        
        // BATCH SIZE - MAXIMIZED FOR A100 80GB
        "batch_size": 32768,  
        "gradient_accumulation_steps": 1,
        
        // GPU CACHING - CRITICAL FOR PERFORMANCE
        "gpu_cache_dataset": true,  // Force GPU caching
        
        // DATALOADER SETTINGS - OPTIMIZED FOR GPU
        "num_workers": 0,  // MUST be 0 for GPU caching
        "pin_memory": false,  // Not needed with GPU cache
        "persistent_workers": false,
        "prefetch_factor": null,
        "drop_last": true,
        
        // Learning rate - scaled with batch size
        "learning_rate": 1e-4,  // 4x original due to 8x batch size (sqrt scaling)
        "weight_decay": 1e-5,
        "betas": [0.9, 0.999],
        "eps": 1e-8,
        "gradient_clip": 5.0,  // Increased for stability with large batches
        
        // Scheduler settings
        "scheduler": "cosine",
        "scheduler_params": {
            "T_0": 50,  // Restart every 10 epochs
            "T_mult": 2,
            "eta_min": 1e-8
        },
        
        // Loss and training settings
        "loss": "mse",
        //"target_relative_error": 0.005, 
        //"track_species_metrics": true, 
        //"loss": "huber",
        //"huber_delta": 0.1,
        "use_amp": false,
        "amp_dtype": "float64",  // Better for A100 than float16
        "early_stopping_patience": 5000,
        "min_delta": 1e-8,
        
        // Reduced logging/memory clearing for performance
        "log_interval": 1000,  // Less frequent logging
        "save_interval": 5,
        "empty_cache_interval": 50000,  // Almost never
        
        // HPO-specific settings
        "hpo_min_epochs": 10,
        "hpo_max_epochs": 40
    },
    
    // ===== SYSTEM/HARDWARE SETTINGS - A100 OPTIMIZED =====
    "system": {
        // Random seed for reproducibility
        "seed": 42,
        
        // PyTorch optimizations for A100
        "use_torch_compile": true,
        "compile_mode": "default",  // Maximum optimization
        "use_torch_export": true,
        
        // CUDA optimizations for A100
        "cudnn_benchmark": true,
        "tf32": false,  // Use TensorFloat-32 on A100
        "dtype": "float64",
        "cuda_memory_fraction": 0.95  // Use most GPU memory
    },
    
    // ===== HYPERPARAMETER OPTIMIZATION =====
    "optuna": {
        // Enable Optuna integration
        "enabled": true,
        
        // Hyperband settings
        "algorithm": "hyperband",
        "hyperband_min_resource": 10,
        "hyperband_max_resource": 50,
        "hyperband_reduction_factor": 3,
        
        // Target number of trials
        "n_trials": 100
    }
}

// ===== A100 OPTIMIZATION NOTES =====
// 
// Key changes from CPU/small GPU config:
// 1. batch_size: 131072 (8x larger) - A100 can handle this easily
// 2. gpu_cache_dataset: true - All data loaded to GPU memory
// 3. num_workers: 0 - No CPU workers needed with GPU cache
// 4. learning_rate: 2e-3 - Scaled with sqrt(batch_size_ratio)
// 5. compile_mode: "max-autotune" - Maximum compilation optimization
// 6. cuda_memory_fraction: 0.95 - Use almost all GPU memory
// 7. amp_dtype: "bfloat16" - Better numerical stability than float16
// 
// Expected performance:
// - GPU utilization: >95%
// - Training speed: ~1-2 minutes per epoch
// - Memory usage: ~20-30GB GPU memory
// 
// If you run out of memory, reduce batch_size to 65536