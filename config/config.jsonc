{
  // ---------- Paths ----------
  "paths": {
    // Where preprocessed shards + manifests live (normalization.json, shard_index.json, …)
    "processed_data_dir": "data/processed",

    // Where checkpoints, logs, CSV, etc. are written
    "work_dir": "models/trained_model",

    // Optional: explicit list of HDF5 files. Leave [] to auto-scan data/raw/*.h5(hdf5)
    "raw_data_files": []
  },

  // ---------- Data schema (authoritative values are re-hydrated from normalization.json) ----------
  "data": {
    // Globals that condition the branch (constant per trajectory)
    "global_variables": ["P", "T"],

    // Name of the absolute time dataset in the raw HDF5
    "time_variable": "t_time",

    // NOTE: species_variables are auto-detected during preprocessing
    // and then injected back into config from normalization.json.

    "species_variables": ["C2H2_evolution",
      "C2H4_evolution",
      "CH3_evolution",
      "CH4_evolution",
      "CO2_evolution",
      "CO_evolution",
      "H2O_evolution",
      "H2_evolution",
      "HCN_evolution",
      "H_evolution",
      "N2_evolution",
      "NH3_evolution",
      "NO_evolution",
      "O2_evolution",
      "OH_evolution",
      "O_evolution"],

    "target_species": [
      "C2H2_evolution",
      "C2H4_evolution",
      "CH3_evolution",
      "CH4_evolution",
      "CO2_evolution",
      "CO_evolution",
      "H2O_evolution",
      "H2_evolution",
      "HCN_evolution",
      "H_evolution",
      "N2_evolution",
      "NH3_evolution",
      "NO_evolution",
      "O2_evolution",
      "OH_evolution",
      "O_evolution"
    ]
  },

  // ---------- Normalization applied everywhere (preprocessor + runtime) ----------
  "normalization": {
    "default_method": "log-standard",
    "methods": {
      "dt":     "log-min-max",
      "t_time": "log-min-max",
      "P":      "log-min-max",
      "T":      "standard"
    },
    "epsilon": 1e-30,
    "min_std": 1e-10,
    "clamp_value": 1e6
  },

  // Preprocessing configuration
  "preprocessing": {
    // Drop any trajectory with values below threshold
    "min_value_threshold": 1e-30,

    // Trajectories per NPZ shard
    "trajectories_per_shard": 65536,

    // NPZ compression off for faster I/O
    "npz_compressed": false,

    // HDF5 scanning workers if not using MPI (ignored with MPI)
    "num_workers": 25,

    // 0 = auto-detect from dataset
    "hdf5_chunk_size": 0
  },

  // ---------- Dataset (pair sampling & loader behavior) ----------
  "dataset": {
    // for quick tests, use less of the data
    "sample_fraction": 0.01,

    "min_dt_phys": 1e-3,   // seconds; null/omitted => no lower bound
    "max_dt_phys": 1e4,     // seconds; null/omitted => no upper bound


    // If all trajectories share the exact same time grid, precompute a [T,T] Δt table (fast path)
    "precompute_dt_table": true,

    // Sample multiple target times per anchor (vectorized trunk; better coverage per batch)
    "multi_time_per_anchor": true,
    "times_per_anchor": 32,          // K; good balance of coverage and memory

    // If grids are shared, reuse the same K offsets across the batch and mask rows that can’t use all
    // Throughput win and more uniform gradients w.r.t. Δt.
    "share_times_across_batch": true,

    // CRITICAL for long-time accuracy: flatten the natural triangular bias of offsets
    "uniform_offset_sampling": false,

    // Put shards on GPU for max throughput (set false if memory is tight)
    "preload_train_to_gpu": false, // should be true for real training
    "preload_val_to_gpu": false, // should be true for real training

    // Loader knobs (ignored when GPU-resident; workers forced to 0)
    "num_workers": 0,
    "pin_memory": false,
    "prefetch_factor": 2,
    "persistent_workers": false
  },

  // ---------- Training (sampler bounds, schedule, regularization) ----------
  "training": {
    // for preprocessing
    "val_fraction": 0.15,
    "test_fraction": 0.1,
    "use_fraction": 1.0,

    "loss_mode": "custom_mse",

    "epochs": 100,

    // Batch sizes (effective compute cost ~ batch_size × times_per_anchor)
    "batch_size": 1024,
    "val_batch_size": 1024,

    // How many anchors per trajectory per epoch (controls epoch length)
    "pairs_per_traj": 1,
    "pairs_per_traj_val": 1,

    // Δt index bounds in steps (NOT seconds). Set max_steps = T-1.
    // If your processed grid has T=100, use 99. This must match the manifest’s grid.
    "min_steps": 1,
    "max_steps": 99,

    // Optimizer (AdamW) + scheduler (linear warmup → cosine)
    "lr": 1e-4,          // lower LR helps stiff transitions
    "min_lr": 1e-6,
    "warmup_epochs": 0,

    // Gentle weight decay (don’t over-regularize the trunk)
    "weight_decay": 1e-5,

    // Clip to tame rare spikes from difficult Δt windows
    "gradient_clip": 1.0,

    // Leave compile off for now (GPU training); turn on only if you profile a win
    "torch_compile": false,

    // 0 means “no cap” (process full loader)
    "max_train_steps_per_epoch": 0,
    "max_val_batches": 0,

    // Restart policy
    "resume": null,
    "auto_resume": true
  },

  // ---------- Model (DeepONet) ----------
  "model": {
    // Basis size (φ·ψ dimension). 512 is the sweet spot for your species count.
    "p": 512,

    // Branch MLP (state+globals → φ)
    "branch_width": 512,
    "branch_depth": 4,

    // Trunk MLP (Δt̂ → ψ). Deep/wide to capture decades-wide stiffness.
    "trunk_layers": [256, 256, 256],

    // Nonlinearity
    "activation": "leakyrelu",

    // Dropout isn’t usually beneficial for these smooth targets; keep it off
    "dropout": 0.0,
    "branch_dropout": 0.0,
    "trunk_dropout": 0.0,

    // Predict Δy and add residual; best for small-to-medium Δt
    "predict_delta": true

  },

  // ---------- Mixed precision ----------
  "mixed_precision": {
    // "bf16" is usually stable on A100/GH200. If you see training noise, switch to "none" for fp32.
    "mode": "bf16"
  },

  // ---------- System / hardware ----------
  "system": {
    "seed": 42,

    // Storage dtype for NPZ + default torch dtype at runtime
    "dtype": "float32",
    "io_dtype": "float32",

    // CPU threading (effective if you ever run CPU-side work)
    "omp_threads": 8,

    // GPU fast-math; safe with bf16/float32
    "tf32": true,
    "cudnn_benchmark": true,

    // Don’t enable deterministic unless reproducing a bug (it hurts speed)
    "deterministic": false
  }
}
